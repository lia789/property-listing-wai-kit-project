2025-09-22 18:47:15 [scrapy.addons] INFO: Enabled addons:
[]
2025-09-22 18:47:15 [asyncio] DEBUG: Using selector: EpollSelector
2025-09-22 18:47:15 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-09-22 18:47:15 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-09-22 18:47:15 [scrapy.extensions.telnet] INFO: Telnet Password: 726e26add41cd976
2025-09-22 18:47:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-09-22 18:47:15 [scrapy.crawler] INFO: Overridden settings:
{'CONCURRENT_REQUESTS': 50,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 50,
 'DOWNLOAD_TIMEOUT': 100,
 'LOG_FILE': 'iproperty_auction_logs.txt',
 'RETRY_HTTP_CODES': [408,
                      429,
                      500,
                      502,
                      503,
                      504,
                      520,
                      521,
                      522,
                      523,
                      524,
                      525,
                      526,
                      527,
                      599,
                      418],
 'RETRY_TIMES': 10}
2025-09-22 18:47:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-09-22 18:47:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-09-22 18:47:15 [scrapy.middleware] INFO: Enabled item pipelines:
['db_pipeline.MySQLStorePipelineBatched']
2025-09-22 18:47:15 [scrapy.core.engine] INFO: Spider opened
2025-09-22 18:47:15 [py.warnings] WARNING: /home/lia/env/lib/python3.13/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: spider.ExampleSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-09-22 18:47:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-09-22 18:47:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-09-22 18:47:16 [py.warnings] WARNING: /home/lia/env/lib/python3.13/site-packages/OpenSSL/crypto.py:1231: CryptographyDeprecationWarning: Parsed a serial number which wasn't positive (i.e., it was negative or zero), which is disallowed by RFC 5280. Loading this certificate will cause an exception in a future release of cryptography.
  return load_der_x509_certificate(der)

2025-09-22 18:47:23 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-09-22 18:47:23 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-09-22 18:47:23 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-09-22 18:47:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.iproperty.com.my/sale/johor-2hh35/apartment-flat/?subChannel=auction&l1&page=1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2025-09-22 18:47:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.iproperty.com.my/sale/selangor-45nk1/apartment-flat/?subChannel=auction&l1&page=1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2025-09-22 18:47:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.iproperty.com.my/sale/penang-5qvq6/apartment-flat/?subChannel=auction&l1&page=1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2025-09-22 18:47:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.iproperty.com.my/sale/kuala-lumpur-58jok/apartment-flat/?subChannel=auction&l1&page=1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2025-09-22 18:47:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 4,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 4,
 'downloader/request_bytes': 1879,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'elapsed_time_seconds': 7.638906,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2025, 9, 22, 12, 47, 23, 439386, tzinfo=datetime.timezone.utc),
 'items_per_minute': 0.0,
 'log_count/DEBUG': 7,
 'log_count/INFO': 12,
 'log_count/WARNING': 2,
 'memusage/max': 69718016,
 'memusage/startup': 69718016,
 'responses_per_minute': 0.0,
 'retry/count': 4,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'start_time': datetime.datetime(2025, 9, 22, 12, 47, 15, 800480, tzinfo=datetime.timezone.utc)}
2025-09-22 18:47:23 [scrapy.core.engine] INFO: Spider closed (shutdown)
