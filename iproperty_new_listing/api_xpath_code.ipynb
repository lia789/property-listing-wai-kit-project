{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e3a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsel import Selector\n",
    "from __future__ import annotations\n",
    "import re\n",
    "from typing import Optional, Tuple\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "\n",
    "\n",
    "# importing the requests library \n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from parsel import Selector\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1042eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lia/env/lib/python3.13/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'proxy-server.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "API_KEY = \"\"\n",
    "proxy = f\"http://scraperapi:{API_KEY}@proxy-server.scraperapi.com:8001\"\n",
    "proxies = {\"http\": proxy, \"https\": proxy}\n",
    "\n",
    "\n",
    "\n",
    "instructions = [\n",
    "    {\n",
    "        \"type\": \"wait_for_selector\",\n",
    "        \"selector\": {\"type\": \"xpath\", \"value\": \"//button[contains(text(), 'See all details')]\"},\n",
    "        \"timeout\": 45,\n",
    "    },\n",
    "    {\"type\": \"wait_for_event\", \"event\": \"stabilize\", \"seconds\": 1},\n",
    "    {\n",
    "        \"type\": \"click\",\n",
    "        \"selector\": {\"type\": \"xpath\", \"value\": \"//button[contains(text(), 'See all details')]\"}\n",
    "    },\n",
    "    {\"type\": \"wait_for_event\", \"event\": \"stabilize\", \"seconds\": 5}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"x-sapi-render\": \"true\",\n",
    "    \"x-sapi-premium\": \"true\",\n",
    "    \"x-sapi-instruction_set\": json.dumps(instructions),\n",
    "    \"x-sapi-device_type\": \"desktop\",\n",
    "    \"x-sapi-retry_404\": \"true\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "url = \"https://www.iproperty.com.my/property/tanjung-tokong/quayside-condominium/sale-100232451/\"\n",
    "r = requests.get(url, headers=headers, proxies=proxies, timeout=60, verify=False)\n",
    "response = Selector(text=r.text)\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15adeff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constants / small utilities ------------------------------------------------\n",
    "\n",
    "# Sentinel for \"Studio\" bedrooms (kept to match your earlier scripts)\n",
    "STUDIO_SENTINEL = 100\n",
    "\n",
    "_NULL_STRS = {\"\", \"na\", \"n/a\", \"none\", \"null\", \"nil\", \"nan\", \"-\"}\n",
    "\n",
    "_NUM_RE = re.compile(r\"[-+]?\\d+(?:\\.\\d+)?\")  # first numeric token (int/float),\n",
    "_WS_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "\n",
    "def _strip(s: Optional[str]) -> Optional[str]:\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = s.strip()\n",
    "    return s if s else None\n",
    "\n",
    "\n",
    "\n",
    "# --- Field-specific cleaners ----------------------------------------------------\n",
    "\n",
    "def split_area(area_state: Optional[str]) -> Optional[str]:\n",
    "    s = _strip(area_state)\n",
    "    if not s:\n",
    "        return None\n",
    "    return s.split(\",\")[0].strip() or None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_list_id(url: Optional[str]) -> Optional[str]:\n",
    "\n",
    "    if not url:\n",
    "        return None\n",
    "    # common \"sale-<digits>\" pattern\n",
    "    m = re.search(r\"(?:sale[-_/])(\\d{6,})\", url)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    # fallback: trailing digits in last path segment\n",
    "    path = urlparse(url).path\n",
    "    parts = [p for p in path.split(\"/\") if p]\n",
    "    if not parts:\n",
    "        return None\n",
    "    last = parts[-1]\n",
    "    m2 = re.search(r\"(\\d{6,})$\", last)\n",
    "    return m2.group(1) if m2 else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_condo_name(name_row: Optional[str]) -> Optional[str]:\n",
    "    s = _strip(name_row)\n",
    "    if not s:\n",
    "        return None\n",
    "    return s.split(\",\")[0].strip() or None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_lat_long_from_url(u: Optional[str]) -> Tuple[Optional[float], Optional[float]]:\n",
    "    try:\n",
    "        if not u:\n",
    "            return (None, None)\n",
    "        q = unquote(u)\n",
    "\n",
    "        m = re.search(r\"markers=[^&]*?(-?\\d+(?:\\.\\d+)?),\\s*(-?\\d+(?:\\.\\d+)?)\", q)\n",
    "        if not m:\n",
    "            m = re.search(r\"center=(-?\\d+(?:\\.\\d+)?),\\s*(-?\\d+(?:\\.\\d+)?)\", q)\n",
    "        if not m:\n",
    "            return (None, None)\n",
    "        lat, lng = float(m.group(1)), float(m.group(2))\n",
    "        return (lat, lng)\n",
    "    except Exception:\n",
    "        return (None, None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def analyze_description(description: Optional[str]) -> dict:\n",
    "    new_launch_keywords = [\n",
    "        \"new launch\", \"rebate\", \"direct developer\", \"early bird\", \"sale package\",\n",
    "        \"new project\", \"free spa legal\", \"free legal\", \"free loan legal\",\n",
    "    ]\n",
    "    auction_keywords = [\"auction\", \"lelong\", \"reserve price\", \"bid\", \"bidding\", \"bidder\", \"bids\"]\n",
    "    urgent_sales_keywords = [\"urgent\", \"must sell\", \"quick sale\"]\n",
    "    below_market_keywords = [\"below market\", \"discount\", \"bargain\", \"fire sale\"]\n",
    "\n",
    "    text = (description or \"\").lower()\n",
    "\n",
    "    def flag(keys):  # 0/1 integers as you used before\n",
    "        return 1 if any(k in text for k in keys) else 0\n",
    "\n",
    "    return {\n",
    "        \"new_project\": flag(new_launch_keywords),\n",
    "        \"auction\": flag(auction_keywords),\n",
    "        \"below_market_value\": flag(below_market_keywords),\n",
    "        \"urgent\": flag(urgent_sales_keywords),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_bedrooms(bed_rooms: Optional[str], studio_value: int = STUDIO_SENTINEL) -> Optional[int]:\n",
    "    if bed_rooms is None:\n",
    "        return None\n",
    "\n",
    "    # primitives\n",
    "    if isinstance(bed_rooms, (int, float)) and not isinstance(bed_rooms, bool):\n",
    "        try:\n",
    "            return int(bed_rooms)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    s = _strip(str(bed_rooms))\n",
    "    if not s:\n",
    "        return None\n",
    "\n",
    "    # take the first comma chunk as \"bedrooms\"\n",
    "    first = s.split(\",\")[0].replace(\" \", \"\").lower()\n",
    "\n",
    "    if first.startswith(\"studio\"):\n",
    "        return studio_value\n",
    "\n",
    "    # sum tokens split by '+', taking only pure digits\n",
    "    parts = re.split(r\"\\+\", first)\n",
    "    nums = [int(p) for p in parts if p.isdigit()]\n",
    "    if nums:\n",
    "        return sum(nums)\n",
    "\n",
    "    # fallback: first number anywhere\n",
    "    m = _NUM_RE.search(first)\n",
    "    return int(float(m.group())) if m else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_int_float(value_row: Optional[str]) -> Optional[float | int]:\n",
    "    if value_row is None:\n",
    "        return None\n",
    "\n",
    "    s = str(value_row).replace(\"\\xa0\", \" \").strip()\n",
    "    if not s or s.lower() in _NULL_STRS:\n",
    "        return None\n",
    "\n",
    "    # Remove common separators so '1,800,000' becomes '1800000'\n",
    "    s = s.replace(\",\", \"\")\n",
    "    m = _NUM_RE.search(s)\n",
    "    if not m:\n",
    "        return None\n",
    "\n",
    "    n = float(m.group())\n",
    "    return int(n) if n.is_integer() else n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_whitespace(text: Optional[str]) -> Optional[str]:\n",
    "    s = _strip(text)\n",
    "    if not s:\n",
    "        return None\n",
    "    return _WS_RE.sub(\" \", s)\n",
    "\n",
    "\n",
    "\n",
    "def clean_posted_date(text):\n",
    "    try:\n",
    "        if text is None:\n",
    "            return None\n",
    "        s = str(text).strip()\n",
    "        if not s:\n",
    "            return None\n",
    "\n",
    "        # match like \"28 Sep 2025\" or \"5 September 2023\" (optional trailing '.')\n",
    "        m = re.search(r'(\\d{1,2})\\s+([A-Za-z]{3,9}\\.?)\\s+(\\d{4})', s)\n",
    "        if not m:\n",
    "            return None\n",
    "\n",
    "        day, mon_raw, year = m.groups()\n",
    "        mon = mon_raw.rstrip('.') \n",
    "        mon = mon[:3].title()\n",
    "        return f\"{int(day)} {mon} {year}\"\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_tenure(tenure_row):\n",
    "    try:\n",
    "        if tenure_row is None:\n",
    "            return None\n",
    "        s = str(tenure_row).strip().strip(\"'\\\"\")\n",
    "        if not s:\n",
    "            return None\n",
    "\n",
    "        # remove 'tenure' with optional colon after it (e.g., \"Tenure: Freehold\")\n",
    "        s = re.sub(r'(?i)\\btenure\\b\\s*:?', '', s)\n",
    "\n",
    "        # collapse extra spaces and trim quotes again\n",
    "        s = re.sub(r'\\s+', ' ', s).strip().strip(\"'\\\"\")\n",
    "        return s or None\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def clean_property_type(property_type_row):\n",
    "    try:\n",
    "        if property_type_row is None:\n",
    "            return None\n",
    "        s = str(property_type_row).strip().strip(\"'\\\"\")\n",
    "        if not s:\n",
    "            return None\n",
    "\n",
    "        # remove \"for sale\" (case-insensitive, allow extra spaces)\n",
    "        s = re.sub(r'(?i)\\bfor\\s*sale\\b', '', s)\n",
    "\n",
    "        # normalize spaces & trim quotes again\n",
    "        s = re.sub(r'\\s+', ' ', s).strip().strip(\"'\\\"\")\n",
    "        return s or None\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def clean_property_title_type(property_title_type_row):\n",
    "    \"\"\"\n",
    "    Removes the word 'title' (case-insensitive) from the string.\n",
    "    Normalizes spaces and trims surrounding quotes.\n",
    "    Returns None on empty/invalid input.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if property_title_type_row is None:\n",
    "            return None\n",
    "        s = str(property_title_type_row).strip().strip(\"'\\\"\")\n",
    "        if not s:\n",
    "            return None\n",
    "\n",
    "        # remove 'title' and any immediate trailing spaces (e.g., \"Strata title\" -> \"Strata\")\n",
    "        s = re.sub(r'(?i)\\btitle\\b\\s*', '', s)\n",
    "\n",
    "        # collapse extra spaces & trim quotes again\n",
    "        s = re.sub(r'\\s+', ' ', s).strip().strip(\"'\\\"\")\n",
    "        return s or None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_lat_lng_from_script(json_text):\n",
    "    try:\n",
    "        if json_text is None:\n",
    "            return (None, None)\n",
    "        m = re.search(\n",
    "            r'\"lat\"\\s*:\\s*(-?\\d+(?:\\.\\d+)?)\\s*,\\s*\"lng\"\\s*:\\s*(-?\\d+(?:\\.\\d+)?)',\n",
    "            str(json_text),\n",
    "            flags=re.DOTALL\n",
    "        )\n",
    "        if not m:\n",
    "            return (None, None)\n",
    "        return float(m.group(1)), float(m.group(2))\n",
    "    except Exception:\n",
    "        return (None, None)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e28ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': None, 'built_up_size': None, 'posted_date': None, 'tenure': None, 'furnished_status': None, 'property_type': None, 'land_title': '', 'property_title_type': None, 'bumi_lot': None, 'built_up_price': None, 'occupancy': None, 'unit_type': '', 'lat': None, 'lng': None, 'description': None, 'new_project': 0, 'auction': 0, 'below_market_value': 0, 'urgent': 0, 'agent_name': '', 'agency_name': '', 'website_name': 'iproperty.com', 'api_update_status': 0, 'agent_profile_url': None, 'parking': None, 'bath': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data extraction xpath code\n",
    "name_row = response.xpath(\"normalize-space(//h1/text())\").get()\n",
    "name = get_condo_name(name_row)\n",
    "\n",
    "tenure = response.xpath(\"normalize-space(//div[contains(text(), 'Tenure')]/following-sibling::div[1]/text())\").get()\n",
    "if not tenure:\n",
    "    tenure = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'tenure')]/text()\").get()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "furnished_status = response.xpath(\"normalize-space(//div[contains(text(), 'Furnishing')]/following-sibling::div[1]/text())\").get()\n",
    "if not furnished_status:\n",
    "    furnished_status = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'furni')]/text()\").get()\n",
    "\n",
    "\n",
    "\n",
    "property_type = response.xpath(\"normalize-space(//div[contains(text(), 'Property type')]/following-sibling::div[1]/text())\").get()\n",
    "if not property_type:\n",
    "    property_type = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'for sale')]/text()\").get()\n",
    "\n",
    "\n",
    "land_title = response.xpath(\"normalize-space(//div[contains(text(), 'Land title')]/following-sibling::div[1]/text())\").get()\n",
    "\n",
    "\n",
    "property_title_type = response.xpath(\"normalize-space(//div[contains(text(), 'Property title type')]/following-sibling::div[1]/text())\").get()\n",
    "if not property_title_type:\n",
    "    property_title_type = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'title')]/text()\").get()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bumi_lot = response.xpath(\"normalize-space(//div[contains(text(), 'Bumi lot')]/following-sibling::div[1]/text())\").get()\n",
    "if not bumi_lot:\n",
    "    bumi_lot = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'Bumi Lot')]/text()\").get()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "built_up_size = response.xpath(\"normalize-space(//div[contains(text(), 'Built-up size')]/following-sibling::div[1]/text())\").get()\n",
    "if not built_up_size:\n",
    "    built_up_size = response.xpath(\"normalize-space(//div[@da-id='amenity-area']/p/text())\").get()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "built_up_price = response.xpath(\"normalize-space(//div[contains(text(), 'Built-up price')]/following-sibling::div[1]/text())\").get()\n",
    "if not built_up_price:\n",
    "    built_up_price = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'psf (floor)')]/text()\").get()\n",
    "\n",
    "\n",
    "\n",
    "occupancy = response.xpath(\"normalize-space(//div[contains(text(), 'Occupancy')]/following-sibling::div[1]/text())\").get()\n",
    "if not occupancy:\n",
    "    occupancy = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'occupied')]/text()\").get()\n",
    "if not occupancy:\n",
    "    occupancy = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'enanted')]/text()\").get()\n",
    "if not occupancy:\n",
    "    occupancy = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'tenanted')]/text()\").get()\n",
    "if not occupancy:\n",
    "    occupancy = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'acant')]/text()\").get()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unit_type = response.xpath(\"normalize-space(//div[contains(text(), 'Unit type')]/following-sibling::div[1]/text())\").get()\n",
    "\n",
    "\n",
    "posted_date = response.xpath(\"normalize-space(//div[contains(text(), 'Posted date')]/following-sibling::div[1]/text())\").get()\n",
    "if not posted_date:\n",
    "    posted_date = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'Listed on')]/text()\").get()\n",
    "\n",
    "\n",
    "\n",
    "# Map â†’ lat/lng\n",
    "google_maps_link = response.xpath(\"//img[contains(@src, 'https://maps.googleapis.com/maps/api/staticmap')]/@src\").get()\n",
    "lat, lng = extract_lat_long_from_url(google_maps_link)\n",
    "\n",
    "if not lat:\n",
    "    lat_lng_json = response.xpath(\"//script[@id='__NEXT_DATA__']/text()\").get()\n",
    "    lat, lng = extract_lat_lng_from_script(lat_lng_json)\n",
    "\n",
    "\n",
    "\n",
    "# Description scraping\n",
    "try:\n",
    "    description_raw = response.xpath(\"//p[@class='sc-c20be062-3 hqRhiu']/text()\").getall()\n",
    "    if description_raw:\n",
    "        description = ' '.join(description_raw)\n",
    "    else:\n",
    "        description = None\n",
    "except Exception as e:\n",
    "    description = None\n",
    "\n",
    "\n",
    "if not description:\n",
    "    try:\n",
    "        description_raw = response.xpath(\"//div[contains(@class, 'description')]/text()\").getall()\n",
    "        if description_raw:\n",
    "            description = ' '.join(description_raw)\n",
    "        else:\n",
    "            description = None\n",
    "    except Exception as e:\n",
    "            description = None\n",
    "\n",
    "\n",
    "\n",
    "# Description analysis\n",
    "des_result = analyze_description(description)\n",
    "new_project = des_result['new_project'] \n",
    "auction = des_result['auction']\n",
    "below_market_value = des_result['below_market_value']\n",
    "urgent = des_result['urgent'] \n",
    "\n",
    "\n",
    "# Agent details\n",
    "agent_name = response.xpath(\"normalize-space(//div[contains(text(), 'REN')]/../a/text())\").get()\n",
    "if not agent_name:\n",
    "    agent_name = response.xpath(\"normalize-space(//div[contains(@class, 'agent-name')]/text())\").get()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agency_name = response.xpath(\"normalize-space(//div[@class='sc-506b84eb-1 cfWLHM']/text())\").get()\n",
    "if not agency_name:\n",
    "    agency_name = response.xpath(\"normalize-space(//div[contains(text(), 'Private Advertiser')]/text())\").get()\n",
    "if not agency_name:\n",
    "    agency_name = response.xpath(\"normalize-space(//div[contains(@class, 'agency')]/text())\").get()\n",
    "\n",
    "\n",
    "agent_profile_url_raw = response.xpath(\"//a[contains(@da-id, 'agent-link')]/@href\").get()\n",
    "if agent_profile_url_raw:\n",
    "    agent_profile_url = f\"https://www.iproperty.com.my{agent_profile_url_raw}\"\n",
    "else:\n",
    "    agent_profile_url = None\n",
    "\n",
    "\n",
    "parking = response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'parking lot')]/text()\").get()\n",
    "bath = response.xpath(\"//p[contains(text(), 'Bath')]/../p/text()\").get()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "item_dic = {\n",
    "    \n",
    "    \"name\": name,\n",
    "    \"built_up_size\": clean_int_float(built_up_size),\n",
    "    \"posted_date\": clean_posted_date(posted_date),\n",
    "\n",
    "\n",
    "    \n",
    "    \"tenure\": clean_tenure(tenure),\n",
    "\n",
    "\n",
    "\n",
    "    \"furnished_status\": furnished_status,\n",
    "    \"property_type\": clean_property_type(property_type),\n",
    "\n",
    "    \"land_title\": land_title, # Not found\n",
    "    \"property_title_type\": clean_property_title_type(property_title_type),\n",
    "    \"bumi_lot\": bumi_lot,\n",
    "\n",
    "    \"built_up_price\": clean_int_float(built_up_price),\n",
    "    \"occupancy\": occupancy,\n",
    "    \"unit_type\": unit_type,  # Not found\n",
    "    \"lat\": lat,\n",
    "    \"lng\": lng,\n",
    "    \"description\": description,\n",
    "    \"new_project\": new_project,\n",
    "    \"auction\": auction,\n",
    "    \"below_market_value\": below_market_value,\n",
    "    \"urgent\": urgent,\n",
    "\n",
    "    \"agent_name\": agent_name,\n",
    "    \"agency_name\": agency_name,\n",
    "    \"website_name\": \"iproperty.com\",\n",
    "    # \"data_scraping_date\": data_scraping_date,\n",
    "    \"api_update_status\": 0,\n",
    "    \"agent_profile_url\": agent_profile_url,\n",
    "    \"parking\": clean_int_float(parking),\n",
    "    \"bath\": clean_int_float(bath),\n",
    "}\n",
    "\n",
    "\n",
    "print(item_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "892ae5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'ten')]/text()\").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cc6f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.xpath(\"//div[@class='property-modal-body-wrapper']//p[contains(text(), 'furni')]/text()\").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e5b83ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = response.xpath(\"//script[@id='__NEXT_DATA__']/text()\").get()\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35673977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.xpath(\"//p[contains(text(), 'Bath')]/../p/text()\").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54df17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a8745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
